[Github Ranking](../README.md)
==========

## Top 100 Stars in LLaMA

| Ranking | Project Name | Stars | Forks | Language | Open Issues | Description | Last Commit |
| ------- | ------------ | ----- | ----- | -------- | ----------- | ----------- | ----------- |
| 1 | [ollama](https://github.com/ollama/ollama) | 131467 | 10800 | Go | 1367 | Get up and running with Llama 3.3, DeepSeek-R1, Phi-4, Gemma 2, and other large language models. | 2025-03-07T01:17:07Z |
| 2 | [llama.cpp](https://github.com/ggml-org/llama.cpp) | 75994 | 10990 | C++ | 359 | LLM inference in C/C++ | 2025-03-07T00:20:35Z |
| 3 | [llama](https://github.com/meta-llama/llama) | 57812 | 9716 | Python | 422 | Inference code for Llama models | 2025-01-26T21:42:26Z |
| 4 | [LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory) | 43270 | 5298 | Python | 339 | Unified Efficient Fine-Tuning of 100+ LLMs & VLMs (ACL 2024) | 2025-03-06T09:14:22Z |
| 5 | [vllm](https://github.com/vllm-project/vllm) | 40524 | 6099 | Python | 1387 | A high-throughput and memory-efficient inference and serving engine for LLMs | 2025-03-07T00:42:50Z |
| 6 | [llama_index](https://github.com/run-llama/llama_index) | 39663 | 5649 | Python | 681 | LlamaIndex is the leading framework for building LLM-powered agents over your data. | 2025-03-07T02:36:36Z |
| 7 | [quivr](https://github.com/QuivrHQ/quivr) | 37469 | 3633 | Python | 25 | Opiniated RAG for integrating GenAI in your apps 🧠   Focus on your product rather than the RAG. Easy integration in existing products with customisation!  Any LLM: GPT4, Groq, Llama. Any Vectorstore: PGVector, Faiss. Any Files. Anyway you want.  | 2025-03-05T18:28:16Z |
| 8 | [Langchain-Chatchat](https://github.com/chatchat-space/Langchain-Chatchat) | 33965 | 5772 | TypeScript | 197 | Langchain-Chatchat（原Langchain-ChatGLM）基于 Langchain 与 ChatGLM, Qwen 与 Llama 等语言模型的 RAG 与 Agent 应用 \| Langchain-Chatchat (formerly langchain-ChatGLM), local knowledge based LLM (like ChatGLM, Qwen and Llama) RAG and Agent app with langchain  | 2024-11-29T05:06:44Z |
| 9 | [unsloth](https://github.com/unslothai/unsloth) | 33696 | 2364 | Python | 820 | Finetune Llama 3.3, DeepSeek-R1 & Reasoning LLMs 2x faster with 70% less memory! 🦥 | 2025-03-06T22:47:44Z |
| 10 | [LocalAI](https://github.com/mudler/LocalAI) | 30867 | 2330 | Go | 407 | :robot: The free, Open Source alternative to OpenAI, Claude and others. Self-hosted and local-first. Drop-in replacement for OpenAI,  running on consumer-grade hardware. No GPU required. Runs gguf, transformers, diffusers and many more models architectures. Features: Generate Text, Audio, Video, Images, Voice Cloning, Distributed, P2P inference | 2025-03-06T22:17:42Z |
| 11 | [aider](https://github.com/Aider-AI/aider) | 28734 | 2607 | Python | 557 | aider is AI pair programming in your terminal | 2025-03-07T00:50:09Z |
| 12 | [llama3](https://github.com/meta-llama/llama3) | 28454 | 3305 | Python | 166 | The official Meta Llama 3 GitHub site | 2025-01-26T21:39:06Z |
| 13 | [khoj](https://github.com/khoj-ai/khoj) | 26552 | 1445 | Python | 70 | Your AI second brain. Self-hostable. Get answers from the web or your docs. Build custom agents, schedule automations, do deep research. Turn any online or local LLM into your personal, autonomous AI (gpt, claude, gemini, llama, qwen, mistral). Get started - free. | 2025-03-04T04:05:37Z |
| 14 | [llamafile](https://github.com/Mozilla-Ocho/llamafile) | 21889 | 1149 | C++ | 167 | Distribute and run LLMs with a single file. | 2025-03-04T21:42:04Z |
| 15 | [LLaVA](https://github.com/haotian-liu/LLaVA) | 21713 | 2384 | Python | 1046 | [NeurIPS'23 Oral] Visual Instruction Tuning (LLaVA) built towards GPT-4V level capabilities and beyond. | 2024-08-12T09:52:38Z |
| 16 | [fish-speech](https://github.com/fishaudio/fish-speech) | 19770 | 1528 | Python | 41 | SOTA Open Source TTS | 2025-03-03T18:44:04Z |
| 17 | [alpaca-lora](https://github.com/tloen/alpaca-lora) | 18827 | 2224 | Jupyter Notebook | 333 | Instruct-tune LLaMA on consumer hardware | 2024-07-29T13:37:49Z |
| 18 | [Chinese-LLaMA-Alpaca](https://github.com/ymcui/Chinese-LLaMA-Alpaca) | 18733 | 1892 | Python | 1 | 中文LLaMA&Alpaca大语言模型+本地CPU/GPU训练部署 (Chinese LLaMA & Alpaca LLMs) | 2024-04-30T04:28:38Z |
| 19 | [Awesome-Chinese-LLM](https://github.com/HqWu-HITCS/Awesome-Chinese-LLM) | 18689 | 1800 | None | 5 | 整理开源的中文大语言模型，以规模较小、可私有化部署、训练成本较低的模型为主，包括底座模型，垂直领域微调及应用，数据集与教程等。 | 2024-09-19T11:06:18Z |
| 20 | [llama2.c](https://github.com/karpathy/llama2.c) | 18132 | 2207 | C | 122 | Inference Llama 2 in one file of pure C | 2024-08-06T09:44:40Z |
| 21 | [llama-cookbook](https://github.com/meta-llama/llama-cookbook) | 16387 | 2360 | Jupyter Notebook | 15 | Welcome to the Llama Cookbook! This is your go to guide for Building with Llama: Getting started with Inference, Fine-Tuning, RAG. We also show you how to solve end to end problems using Llama model family and using them on various provider services   | 2025-03-06T16:24:39Z |
| 22 | [ChuanhuChatGPT](https://github.com/GaiZhenbiao/ChuanhuChatGPT) | 15388 | 2292 | Python | 124 | GUI for ChatGPT API and many LLMs. Supports agents, file-based QA, GPT finetuning and query with web search. All with a neat UI. | 2025-02-26T10:59:31Z |
| 23 | [Llama-Chinese](https://github.com/LlamaFamily/Llama-Chinese) | 14464 | 1292 | Python | 196 | Llama中文社区，Llama3在线体验和微调模型已开放，实时汇总最新Llama3学习资料，已将所有代码更新适配Llama3，构建最好的中文Llama大模型，完全开源可商用 | 2024-09-05T13:50:43Z |
| 24 | [MaxKB](https://github.com/1Panel-dev/MaxKB) | 14236 | 1881 | Python | 92 | 💬 Ready-to-use & flexible RAG Chatbot, supporting mainstream large language models (LLMs) such as DeepSeek-R1, Llama 3.3, Qwen2, OpenAI and more. | 2025-03-07T02:19:59Z |
| 25 | [llama3-from-scratch](https://github.com/naklecha/llama3-from-scratch) | 14227 | 1166 | Jupyter Notebook | 13 | llama3 implementation one matrix multiplication at a time | 2024-05-23T14:34:05Z |
| 26 | [dalai](https://github.com/cocktailpeanut/dalai) | 13084 | 1407 | CSS | 293 | The simplest way to run LLaMA on your local machine | 2024-06-18T20:29:46Z |
| 27 | [repomix](https://github.com/yamadashy/repomix) | 12460 | 528 | TypeScript | 51 | 📦 Repomix (formerly Repopack) is a powerful tool that packs your entire repository into a single, AI-friendly file. Perfect for when you need to feed your codebase to Large Language Models (LLMs) or other AI tools like Claude, ChatGPT, DeepSeek, Perplexity, Gemini, Gemma, Llama, Grok, and more. | 2025-03-06T14:47:40Z |
| 28 | [PaddleNLP](https://github.com/PaddlePaddle/PaddleNLP) | 12404 | 2995 | Python | 319 | 👑 Easy-to-use and powerful NLP and LLM library with 🤗 Awesome model zoo, supporting wide-range of NLP tasks from research to industrial applications, including 🗂Text Classification,  🔍 Neural Search, ❓ Question Answering, ℹ️ Information Extraction, 📄 Document Intelligence, 💌 Sentiment Analysis etc.  | 2025-03-07T03:25:16Z |
| 29 | [h2ogpt](https://github.com/h2oai/h2ogpt) | 11711 | 1286 | Python | 283 | Private chat with local GPT with document, images, video, etc. 100% private, Apache 2.0. Supports oLLaMa, Mixtral, llama.cpp, and more. Demo: https://gpt.h2o.ai/ https://gpt-docs.h2o.ai/ | 2025-02-25T08:08:30Z |
| 30 | [sglang](https://github.com/sgl-project/sglang) | 11493 | 1160 | Python | 331 | SGLang is a fast serving framework for large language models and vision language models. | 2025-03-07T02:05:45Z |
| 31 | [ludwig](https://github.com/ludwig-ai/ludwig) | 11353 | 1201 | Python | 38 | Low-code framework for building custom LLMs, neural networks, and other AI models | 2025-03-03T20:40:07Z |
| 32 | [llama-gpt](https://github.com/getumbrel/llama-gpt) | 10946 | 717 | TypeScript | 84 | A self-hosted, offline, ChatGPT-like chatbot. Powered by Llama 2. 100% private, with no data leaving your device. New: Code Llama support! | 2024-04-23T18:56:06Z |
| 33 | [OpenLLM](https://github.com/bentoml/OpenLLM) | 10900 | 691 | Python | 0 | Run any open-source LLMs, such as DeepSeek and Llama, as OpenAI compatible API endpoint in the cloud. | 2025-03-03T20:40:11Z |
| 34 | [shell_gpt](https://github.com/TheR1D/shell_gpt) | 10456 | 825 | Python | 81 | A command-line productivity tool powered by AI large language models like GPT-4, will help you accomplish your tasks faster and more efficiently. | 2025-02-17T04:11:14Z |
| 35 | [mastra](https://github.com/mastra-ai/mastra) | 9487 | 413 | TypeScript | 47 | The TypeScript AI agent framework. ⚡ Assistants, RAG, observability. Supports any LLM: GPT-4, Claude, Gemini, Llama. | 2025-03-07T03:04:00Z |
| 36 | [petals](https://github.com/bigscience-workshop/petals) | 9484 | 541 | Python | 90 | 🌸 Run LLMs at home, BitTorrent-style. Fine-tuning and inference up to 10x faster than offloading | 2024-09-07T11:54:28Z |
| 37 | [llama-cpp-python](https://github.com/abetlen/llama-cpp-python) | 8773 | 1073 | Python | 519 | Python bindings for llama.cpp | 2025-03-04T20:35:45Z |
| 38 | [TinyLlama](https://github.com/jzhang38/TinyLlama) | 8271 | 510 | Python | 42 | The TinyLlama project is an open endeavor to pretrain a 1.1B Llama model on 3 trillion tokens. | 2024-05-03T20:21:20Z |
| 39 | [PowerInfer](https://github.com/SJTU-IPADS/PowerInfer) | 8138 | 424 | C++ | 104 | High-speed Large Language Model Serving for Local Deployment | 2025-02-19T08:15:55Z |
| 40 | [BELLE](https://github.com/LianjiaTech/BELLE) | 8065 | 767 | HTML | 104 | BELLE: Be Everyone's Large Language model Engine（开源中文对话大模型） | 2024-10-16T11:38:59Z |
| 41 | [bisheng](https://github.com/dataelement/bisheng) | 7777 | 1313 | Python | 74 | BISHENG is an open LLM devops platform for next generation Enterprise AI applications. Powerful and comprehensive features include: GenAI workflow, RAG, Agent, Unified model management, Evaluation, SFT, Dataset Management, Enterprise-level System Management, Observability and more. | 2025-03-06T10:45:26Z |
| 42 | [reor](https://github.com/reorproject/reor) | 7706 | 464 | TypeScript | 108 | Private & local AI personal knowledge management app for high entropy people. | 2025-03-01T17:29:48Z |
| 43 | [open_llama](https://github.com/openlm-research/open_llama) | 7454 | 395 | None | 36 | OpenLLaMA, a permissively licensed open source reproduction of Meta AI’s LLaMA 7B trained on the RedPajama dataset | 2023-07-16T13:42:13Z |
| 44 | [GPTCache](https://github.com/zilliztech/GPTCache) | 7440 | 529 | Python | 71 | Semantic cache for LLMs. Fully integrated with LangChain and llama_index.  | 2024-09-18T02:05:21Z |
| 45 | [llama-stack](https://github.com/meta-llama/llama-stack) | 7432 | 912 | Python | 143 | Composable building blocks to build Llama Apps | 2025-03-07T03:24:07Z |
| 46 | [ipex-llm](https://github.com/intel/ipex-llm) | 7399 | 1318 | Python | 1081 | Accelerate local LLM inference and finetuning (LLaMA, Mistral, ChatGLM, Qwen, DeepSeek, Mixtral, Gemma, Phi, MiniCPM, Qwen-VL, MiniCPM-V, etc.) on Intel XPU (e.g., local PC with iGPU and NPU, discrete GPU such as Arc, Flex and Max); seamlessly integrate with llama.cpp, Ollama, HuggingFace, LangChain, LlamaIndex, vLLM, DeepSpeed, Axolotl, etc. | 2025-03-07T01:20:41Z |
| 47 | [Chinese-LLaMA-Alpaca-2](https://github.com/ymcui/Chinese-LLaMA-Alpaca-2) | 7157 | 577 | Python | 1 | 中文LLaMA-2 & Alpaca-2大模型二期项目 + 64K超长上下文模型 (Chinese LLaMA-2 & Alpaca-2 LLMs with 64K long context models) | 2024-09-23T02:52:19Z |
| 48 | [inference](https://github.com/xorbitsai/inference) | 6846 | 562 | Python | 166 | Replace OpenAI GPT with another LLM in your app by changing a single line of code. Xinference gives you the freedom to use any LLM you need. With Xinference, you're empowered to run inference with any open-source language models, speech recognition models, and multimodal models, whether in the cloud, on-premises, or even on your laptop. | 2025-03-06T08:29:32Z |
| 49 | [k8sgpt](https://github.com/k8sgpt-ai/k8sgpt) | 6327 | 759 | Go | 66 | Giving Kubernetes Superpowers to everyone | 2025-03-06T18:17:32Z |
| 50 | [Firefly](https://github.com/yangjianxin1/Firefly) | 6229 | 557 | Python | 204 | Firefly: 大模型训练工具，支持训练Qwen2.5、Qwen2、Yi1.5、Phi-3、Llama3、Gemma、MiniCPM、Yi、Deepseek、Orion、Xverse、Mixtral-8x7B、Zephyr、Mistral、Baichuan2、Llma2、Llama、Qwen、Baichuan、ChatGLM2、InternLM、Ziya2、Vicuna、Bloom等大模型 | 2024-10-24T02:27:42Z |
| 51 | [langchain4j](https://github.com/langchain4j/langchain4j) | 6198 | 1179 | Java | 356 | Java version of LangChain | 2025-03-05T10:50:16Z |
| 52 | [ms-swift](https://github.com/modelscope/ms-swift) | 6063 | 519 | Python | 428 | Use PEFT or Full-parameter to finetune 450+ LLMs (Qwen2.5, InternLM3, GLM4, Llama3.3, Mistral, Yi1.5, Baichuan2, DeepSeek-R1, ...) and 150+ MLLMs (Qwen2.5-VL, Qwen2-Audio, Llama3.2-Vision, Llava, InternVL2.5, MiniCPM-V-2.6, GLM4v, Xcomposer2.5, Yi-VL, DeepSeek-VL2, Phi3.5-Vision, GOT-OCR2, ...). | 2025-03-07T01:56:41Z |
| 53 | [lit-llama](https://github.com/Lightning-AI/lit-llama) | 6036 | 520 | Python | 109 | Implementation of the LLaMA language model based on nanoGPT. Supports flash attention, Int8 and GPTQ 4bit quantization, LoRA and LLaMA-Adapter fine-tuning, pre-training. Apache 2.0-licensed. | 2024-09-06T11:38:12Z |
| 54 | [LaWGPT](https://github.com/pengxiao-song/LaWGPT) | 5922 | 546 | Python | 86 |  🎉 Repo for LaWGPT, Chinese-Llama tuned with Chinese Legal knowledge. 基于中文法律知识的大语言模型 | 2024-06-11T07:20:19Z |
| 55 | [llama-models](https://github.com/meta-llama/llama-models) | 5882 | 1000 | Python | 85 | Utilities intended for use with Llama models. | 2025-03-01T18:35:13Z |
| 56 | [LLaMA-Adapter](https://github.com/OpenGVLab/LLaMA-Adapter) | 5822 | 379 | Python | 106 | [ICLR 2024] Fine-tuning LLaMA to follow Instructions within 1 Hour and 1.2M Parameters | 2024-03-14T08:12:53Z |
| 57 | [lmdeploy](https://github.com/InternLM/lmdeploy) | 5778 | 503 | Python | 367 | LMDeploy is a toolkit for compressing, deploying, and serving LLMs. | 2025-03-06T03:44:25Z |
| 58 | [promptfoo](https://github.com/promptfoo/promptfoo) | 5746 | 475 | TypeScript | 152 | Test your prompts, agents, and RAGs. Red teaming, pentesting, and vulnerability scanning for LLMs. Compare performance of GPT, Claude, Gemini, Llama, and more. Simple declarative configs with command line and CI/CD integration. | 2025-03-07T01:16:30Z |
| 59 | [airllm](https://github.com/lyogavin/airllm) | 5721 | 456 | Jupyter Notebook | 109 | AirLLM 70B inference with single 4GB GPU | 2024-11-24T23:32:29Z |
| 60 | [serge](https://github.com/serge-chat/serge) | 5701 | 403 | Svelte | 18 | A web interface for chatting with Alpaca through llama.cpp. Fully dockerized, with an easy to use API. | 2025-03-06T08:44:16Z |
| 61 | [Baichuan-7B](https://github.com/baichuan-inc/Baichuan-7B) | 5693 | 509 | Python | 85 | A large-scale 7B pretraining language model developed by BaiChuan-Inc. | 2024-07-18T14:23:01Z |
| 62 | [llamacoder](https://github.com/Nutlope/llamacoder) | 5634 | 1211 | TypeScript | 36 | Open source Claude Artifacts – built with Llama 3.1 405B | 2025-01-22T11:28:23Z |
| 63 | [AstrBot](https://github.com/Soulter/AstrBot) | 5526 | 324 | Python | 125 | ✨ 易上手的多平台 LLM 聊天机器人及开发框架 ✨ 平台支持 QQ、QQ频道、Telegram、微信、企微、飞书 \| OpenAI、DeepSeek、Gemini、硅基流动、月之暗面、Ollama、OneAPI、Dify 等。附带 WebUI。 | 2025-03-07T02:52:09Z |
| 64 | [mergekit](https://github.com/arcee-ai/mergekit) | 5366 | 508 | Python | 196 | Tools for merging pretrained large language models. | 2025-03-03T03:12:01Z |
| 65 | [llama-fs](https://github.com/iyaja/llama-fs) | 5185 | 325 | TypeScript | 44 | A self-organizing file system with llama 3 | 2025-02-18T01:58:14Z |
| 66 | [enchanted](https://github.com/gluonfield/enchanted) | 4975 | 312 | Swift | 88 | Enchanted is iOS and macOS app for chatting with private self hosted language models such as Llama2, Mistral or Vicuna using Ollama. | 2025-01-27T21:47:06Z |
| 67 | [llm-answer-engine](https://github.com/developersdigest/llm-answer-engine) | 4862 | 766 | TypeScript | 25 | Build a Perplexity-Inspired Answer Engine Using Next.js, Groq, Llama-3, Langchain, OpenAI, Upstash, Brave & Serper | 2024-09-28T16:41:53Z |
| 68 | [Huatuo-Llama-Med-Chinese](https://github.com/SCIR-HI/Huatuo-Llama-Med-Chinese) | 4693 | 473 | Python | 26 | Repo for BenTsao [original name: HuaTuo (华驼)], Instruction-tuning Large Language Models with Chinese Medical Knowledge. 本草（原名：华驼）模型仓库，基于中文医学知识的大语言模型指令微调 | 2025-02-21T02:04:37Z |
| 69 | [Liger-Kernel](https://github.com/linkedin/Liger-Kernel) | 4565 | 276 | Python | 48 | Efficient Triton Kernels for LLM Training | 2025-03-07T01:19:19Z |
| 70 | [llm-scraper](https://github.com/mishushakov/llm-scraper) | 4543 | 262 | TypeScript | 11 | Turn any webpage into structured data using LLMs | 2024-08-30T17:36:16Z |
| 71 | [GPT-4-LLM](https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM) | 4279 | 303 | HTML | 13 | Instruction Tuning with GPT-4 | 2023-06-11T13:40:30Z |
| 72 | [YuE](https://github.com/multimodal-art-projection/YuE) | 4263 | 456 | Python | 42 | YuE: Open Full-song Music Generation Foundation Model, something similar to Suno.ai but open | 2025-03-01T04:29:00Z |
| 73 | [h2o-llmstudio](https://github.com/h2oai/h2o-llmstudio) | 4204 | 439 | Python | 36 | H2O LLM Studio - a framework and no-code GUI for fine-tuning LLMs. Documentation: https://docs.h2o.ai/h2o-llmstudio/ | 2025-03-05T19:45:56Z |
| 74 | [g1](https://github.com/bklieger-groq/g1) | 4190 | 378 | Python | 1 | g1: Using Llama-3.1 70b on Groq to create o1-like reasoning chains | 2025-01-27T18:36:13Z |
| 75 | [llama-dl](https://github.com/shawwn/llama-dl) | 4166 | 418 | Shell | 9 | High-speed download of LLaMA, Facebook's 65B parameter GPT model | 2023-06-28T16:56:55Z |
| 76 | [llama-stack-apps](https://github.com/meta-llama/llama-stack-apps) | 4159 | 613 | None | 19 | Agentic components of the Llama Stack APIs | 2025-03-07T03:22:52Z |
| 77 | [Chinese-Vicuna](https://github.com/Facico/Chinese-Vicuna) | 4152 | 419 | C | 65 | Chinese-Vicuna: A Chinese Instruction-following LLaMA-based Model —— 一个中文低资源的llama+lora方案，结构参考alpaca | 2024-11-14T12:37:47Z |
| 78 | [llama3-Chinese-chat](https://github.com/CrazyBoyM/llama3-Chinese-chat) | 4137 | 339 | Python | 29 | Llama3、Llama3.1 中文仓库（随书籍撰写中...  各种网友及厂商微调、魔改版本有趣权重 & 训练、推理、评测、部署教程视频 & 文档） | 2024-09-16T10:05:58Z |
| 79 | [awesome-LLM-resourses](https://github.com/WangRongsheng/awesome-LLM-resourses) | 3929 | 417 | None | 0 | 🧑‍🚀 全世界最好的LLM资料总结（数据处理、模型训练、模型部署、o1 模型、小语言模型、视觉语言模型） \| Summary of the world's best LLM resources.  | 2025-03-06T04:05:38Z |
| 80 | [data-juicer](https://github.com/modelscope/data-juicer) | 3850 | 214 | Python | 26 | Data processing for and with foundation models!  🍎 🍋 🌽 ➡️ ➡️🍸 🍹 🍷 | 2025-03-07T02:27:00Z |
| 81 | [llama_cloud_services](https://github.com/run-llama/llama_cloud_services) | 3753 | 369 | Python | 228 | Knowledge Agents and Management in the Cloud | 2025-03-07T02:24:28Z |
| 82 | [MedicalGPT](https://github.com/shibing624/MedicalGPT) | 3664 | 536 | Python | 36 | MedicalGPT: Training Your Own Medical GPT Model with ChatGPT Training Pipeline. 训练医疗大模型，实现了包括增量预训练(PT)、有监督微调(SFT)、RLHF、DPO、ORPO、GRPO。 | 2025-03-06T12:30:47Z |
| 83 | [llama-hub](https://github.com/run-llama/llama-hub) | 3469 | 738 | Jupyter Notebook | 82 | A library of data loaders for LLMs made by the community -- to be used with LlamaIndex and/or LangChain | 2024-03-01T15:17:16Z |
| 84 | [fastllm](https://github.com/ztxz16/fastllm) | 3407 | 348 | C++ | 234 | 纯c++的全平台llm加速库，支持python调用，chatglm-6B级模型单卡可达10000+token / s，支持glm, llama, moss基座，手机端流畅运行 | 2025-03-06T06:55:12Z |
| 85 | [obsidian-smart-connections](https://github.com/brianpetro/obsidian-smart-connections) | 3372 | 198 | JavaScript | 338 | Chat with your notes & see links to related content with AI embeddings. Use local models or 100+ via APIs like Claude, Gemini, ChatGPT & Llama 3 | 2025-03-04T01:00:25Z |
| 86 | [higgsfield](https://github.com/higgsfield-ai/higgsfield) | 3320 | 557 | Jupyter Notebook | 1 | Fault-tolerant, highly scalable GPU orchestration, and a machine learning framework designed for training models with billions to trillions of parameters | 2024-05-25T17:43:07Z |
| 87 | [zero_nlp](https://github.com/yuanzhoulvpi2017/zero_nlp) | 3279 | 393 | Jupyter Notebook | 96 | 中文nlp解决方案(大模型、数据、模型、训练、推理)  | 2025-02-12T13:56:56Z |
| 88 | [YAYI](https://github.com/wenge-research/YAYI) | 3265 | 43 | Python | 0 | 雅意大模型：为客户打造安全可靠的专属大模型，基于大规模中英文多领域指令数据训练的 LlaMA 2 & BLOOM 系列模型，由中科闻歌算法团队研发。(Repo for YaYi Chinese LLMs based on LlaMA2 & BLOOM) | 2024-01-17T07:37:16Z |
| 89 | [LangChain-ChatGLM-Webui](https://github.com/X-D-Lab/LangChain-ChatGLM-Webui) | 3239 | 489 | Python | 45 | 基于LangChain和ChatGLM-6B等系列LLM的针对本地知识库的自动问答 | 2024-04-15T15:03:05Z |
| 90 | [InternGPT](https://github.com/OpenGVLab/InternGPT) | 3215 | 231 | Python | 19 | InternGPT (iGPT) is an open source demo platform where you can easily showcase your AI models. Now it supports DragGAN, ChatGPT, ImageBind, multimodal chat like GPT-4, SAM, interactive image editing, etc. Try it at igpt.opengvlab.com (支持DragGAN、ChatGPT、ImageBind、SAM的在线Demo系统) | 2024-08-20T12:51:03Z |
| 91 | [casibase](https://github.com/casibase/casibase) | 3139 | 386 | Go | 35 | AI Cloud OS: ⚡️Open-source RAG knowledge database with admin UI, user management and Single-Sign-On⚡️, supports ChatGPT, Claude, DeepSeek R1, Llama, Gemini, HuggingFace, etc., chat bot demo: https://ai.casibase.com, admin UI demo: https://ai-admin.casibase.com | 2025-03-05T16:11:41Z |
| 92 | [langroid](https://github.com/langroid/langroid) | 3121 | 299 | Python | 51 | Harness LLMs with Multi-Agent Programming | 2025-03-06T14:37:05Z |
| 93 | [Linly](https://github.com/CVI-SZU/Linly) | 3048 | 234 | Python | 109 | Chinese-LLaMA 1&2、Chinese-Falcon 基础模型；ChatFlow中文对话模型；中文OpenLLaMA模型；NLP预训练/指令微调数据集 | 2024-04-14T05:19:19Z |
| 94 | [GPTQ-for-LLaMa](https://github.com/qwopqwop200/GPTQ-for-LLaMa) | 3042 | 461 | Python | 61 | 4 bits quantization of LLaMA using GPTQ | 2024-07-13T04:45:28Z |
| 95 | [LLamaSharp](https://github.com/SciSharp/LLamaSharp) | 3021 | 394 | C# | 154 | A C#/.NET library to run LLM (🦙LLaMA/LLaVA) on your local device efficiently. | 2025-03-01T13:48:31Z |
| 96 | [lightllm](https://github.com/ModelTC/lightllm) | 2985 | 232 | Python | 67 | LightLLM is a Python-based LLM (Large Language Model) inference and serving framework, notable for its lightweight design, easy scalability, and high-speed performance. | 2025-03-07T03:23:58Z |
| 97 | [PurpleLlama](https://github.com/meta-llama/PurpleLlama) | 2940 | 490 | Python | 8 | Set of tools to assess and improve LLM security. | 2025-02-14T21:34:34Z |
| 98 | [Video-LLaMA](https://github.com/DAMO-NLP-SG/Video-LLaMA) | 2938 | 269 | Python | 61 | [EMNLP 2023 Demo] Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video Understanding | 2024-06-04T07:06:41Z |
| 99 | [AGiXT](https://github.com/Josh-XT/AGiXT) | 2922 | 389 | Python | 7 | AGiXT is a dynamic AI Agent Automation Platform that seamlessly orchestrates instruction management and complex task execution across diverse AI providers. Combining adaptive memory, smart features, and a versatile plugin system, AGiXT delivers efficient and comprehensive AI solutions. | 2025-02-27T04:52:07Z |
| 100 | [tensorzero](https://github.com/tensorzero/tensorzero) | 2863 | 172 | Rust | 111 | TensorZero creates a feedback loop for optimizing LLM applications — turning production data into smarter, faster, and cheaper models. | 2025-03-07T03:14:27Z |

