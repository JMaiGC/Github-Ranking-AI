[Github Ranking](../README.md)
==========

## Top 100 Stars in Mistral

| Ranking | Project Name | Stars | Forks | Language | Open Issues | Description | Last Commit |
| ------- | ------------ | ----- | ----- | -------- | ----------- | ----------- | ----------- |
| 1 | [ollama](https://github.com/ollama/ollama) | 143514 | 12059 | Go | 1571 | Get up and running with Llama 3.3, DeepSeek-R1, Phi-4, Gemma 3, Mistral Small 3.1 and other large language models. | 2025-06-12T21:18:55Z |
| 2 | [LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory) | 52173 | 6298 | Python | 484 | Unified Efficient Fine-Tuning of 100+ LLMs & VLMs (ACL 2024) | 2025-06-12T08:10:38Z |
| 3 | [unsloth](https://github.com/unslothai/unsloth) | 40476 | 3209 | Python | 795 | Fine-tuning & Reinforcement Learning for LLMs. 🦥 Train Qwen3, Llama 4, DeepSeek-R1, Gemma 3, TTS 2x faster with 70% less VRAM. | 2025-06-12T08:23:36Z |
| 4 | [LocalAI](https://github.com/mudler/LocalAI) | 33186 | 2543 | Go | 457 | :robot: The free, Open Source alternative to OpenAI, Claude and others. Self-hosted and local-first. Drop-in replacement for OpenAI,  running on consumer-grade hardware. No GPU required. Runs gguf, transformers, diffusers and many more models architectures. Features: Generate Text, Audio, Video, Images, Voice Cloning, Distributed, P2P inference | 2025-06-12T21:33:34Z |
| 5 | [khoj](https://github.com/khoj-ai/khoj) | 30314 | 1712 | Python | 75 | Your AI second brain. Self-hostable. Get answers from the web or your docs. Build custom agents, schedule automations, do deep research. Turn any online or local LLM into your personal, autonomous AI (gpt, claude, gemini, llama, qwen, mistral). Get started - free. | 2025-06-11T20:37:52Z |
| 6 | [LibreChat](https://github.com/danny-avila/LibreChat) | 26693 | 4676 | TypeScript | 163 | Enhanced ChatGPT Clone: Features Agents, DeepSeek, Anthropic, AWS, OpenAI, Assistants API, Azure, Groq, o1, GPT-4o, Mistral, OpenRouter, Vertex AI, Gemini, Artifacts, AI model switching, message search, Code Interpreter, langchain, DALL-E-3, OpenAPI Actions, Functions, Secure Multi-User Auth, Presets, open-source for self-hosting. Active project. | 2025-06-12T21:34:06Z |
| 7 | [ludwig](https://github.com/ludwig-ai/ludwig) | 11489 | 1215 | Python | 42 | Low-code framework for building custom LLMs, neural networks, and other AI models | 2025-06-02T20:17:35Z |
| 8 | [OpenLLM](https://github.com/bentoml/OpenLLM) | 11347 | 727 | Python | 2 | Run any open-source LLMs, such as DeepSeek and Llama, as OpenAI compatible API endpoint in the cloud. | 2025-06-10T02:34:52Z |
| 9 | [mistral-inference](https://github.com/mistralai/mistral-inference) | 10292 | 921 | Jupyter Notebook | 126 | Official inference library for Mistral models | 2025-03-20T15:03:08Z |
| 10 | [inference](https://github.com/xorbitsai/inference) | 8027 | 685 | Python | 159 | Replace OpenAI GPT with another LLM in your app by changing a single line of code. Xinference gives you the freedom to use any LLM you need. With Xinference, you're empowered to run inference with any open-source language models, speech recognition models, and multimodal models, whether in the cloud, on-premises, or even on your laptop. | 2025-06-12T10:20:45Z |
| 11 | [ipex-llm](https://github.com/intel/ipex-llm) | 8015 | 1351 | Python | 1175 | Accelerate local LLM inference and finetuning (LLaMA, Mistral, ChatGLM, Qwen, DeepSeek, Mixtral, Gemma, Phi, MiniCPM, Qwen-VL, MiniCPM-V, etc.) on Intel XPU (e.g., local PC with iGPU and NPU, discrete GPU such as Arc, Flex and Max); seamlessly integrate with llama.cpp, Ollama, HuggingFace, LangChain, LlamaIndex, vLLM, DeepSpeed, Axolotl, etc. | 2025-06-11T02:08:44Z |
| 12 | [big-AGI](https://github.com/enricoros/big-AGI) | 6462 | 1512 | TypeScript | 245 | AI suite powered by state-of-the-art models and providing advanced AI/AGI functions. It features AI personas, AGI functions, multi-model chats, text-to-image, voice, response streaming, code highlighting and execution, PDF import, presets for developers, much more. Deploy on-prem or in the cloud. | 2025-06-12T21:16:09Z |
| 13 | [Firefly](https://github.com/yangjianxin1/Firefly) | 6445 | 581 | Python | 204 | Firefly: 大模型训练工具，支持训练Qwen2.5、Qwen2、Yi1.5、Phi-3、Llama3、Gemma、MiniCPM、Yi、Deepseek、Orion、Xverse、Mixtral-8x7B、Zephyr、Mistral、Baichuan2、Llma2、Llama、Qwen、Baichuan、ChatGLM2、InternLM、Ziya2、Vicuna、Bloom等大模型 | 2024-10-24T02:27:42Z |
| 14 | [mistral.rs](https://github.com/EricLBuehler/mistral.rs) | 5723 | 413 | Rust | 137 | Blazingly fast LLM inference. | 2025-06-12T03:35:56Z |
| 15 | [opencompass](https://github.com/open-compass/opencompass) | 5500 | 596 | Python | 314 | OpenCompass is an LLM evaluation platform, supporting a wide range of models (Llama3, Mistral, InternLM2,GPT-4,LLaMa2, Qwen,GLM, Claude, etc) over 100+ datasets. | 2025-06-13T03:21:48Z |
| 16 | [awesome-LLM-resources](https://github.com/WangRongsheng/awesome-LLM-resources) | 5437 | 536 | None | 0 | 🧑‍🚀 全世界最好的LLM资料总结（视频生成、Agent、辅助编程、数据处理、模型训练、模型推理、o1 模型、MCP、小语言模型、视觉语言模型） \| Summary of the world's best LLM resources.  | 2025-06-09T05:46:08Z |
| 17 | [enchanted](https://github.com/gluonfield/enchanted) | 5406 | 354 | Swift | 95 | Enchanted is iOS and macOS app for chatting with private self hosted language models such as Llama2, Mistral or Vicuna using Ollama. | 2025-03-19T20:19:21Z |
| 18 | [Liger-Kernel](https://github.com/linkedin/Liger-Kernel) | 5187 | 347 | Python | 58 | Efficient Triton Kernels for LLM Training | 2025-06-12T18:35:36Z |
| 19 | [xtuner](https://github.com/InternLM/xtuner) | 4590 | 348 | Python | 218 | An efficient, flexible and full-featured toolkit for fine-tuning LLM (InternLM2, Llama3, Phi3, Qwen, Mistral, ...) | 2025-05-29T15:17:57Z |
| 20 | [agentops](https://github.com/AgentOps-AI/agentops) | 4543 | 415 | Python | 69 | Python SDK for AI agent monitoring, LLM cost tracking, benchmarking, and more. Integrates with most LLMs and agent frameworks including OpenAI Agents SDK, CrewAI, Langchain, Autogen, AG2, and CamelAI | 2025-06-12T21:22:10Z |
| 21 | [chinese-llm-benchmark](https://github.com/jeinlee1991/chinese-llm-benchmark) | 4353 | 181 | None | 30 | 目前已囊括243个大模型，覆盖chatgpt、gpt-4.1、o4-mini、谷歌gemini-2.5、Claude、智谱GLM-Z1、文心一言、qwen-max、百川、讯飞星火、商汤senseChat、minimax等商用模型， 以及DeepSeek-R1-0528、qwq-32b、deepseek-v3、qwen3、llama4、phi-4、glm4、gemma3、mistral、书生internLM2.5等开源大模型。不仅提供排行榜，也提供规模超200万的大模型缺陷库！方便广大社区研究分析、改进大模型。 | 2025-06-12T12:42:36Z |
| 22 | [paperless-ai](https://github.com/clusterzx/paperless-ai) | 3534 | 131 | JavaScript | 14 | An automated document analyzer for Paperless-ngx using OpenAI API, Ollama, Deepseek-r1, Azure and all OpenAI API compatible Services to automatically analyze and tag your documents. | 2025-06-10T17:36:18Z |
| 23 | [AI-Infra-from-Zero-to-Hero](https://github.com/HuaizhengZhang/AI-Infra-from-Zero-to-Hero) | 2983 | 325 | None | 13 | 🚀 Awesome System for Machine Learning ⚡️ AI System Papers and Industry Practice. ⚡️ System for Machine Learning, LLM (Large Language Model), GenAI (Generative AI). 🍻 OSDI, NSDI, SIGCOMM, SoCC, MLSys, etc. 🗃️ Llama3, Mistral, etc. 🧑‍💻 Video Tutorials.  | 2025-05-24T18:29:12Z |
| 24 | [mistral-finetune](https://github.com/mistralai/mistral-finetune) | 2957 | 276 | Python | 33 | None | 2024-09-13T09:53:13Z |
| 25 | [local-deep-research](https://github.com/LearningCircuit/local-deep-research) | 2848 | 284 | Python | 28 | Local Deep Research is an AI-powered assistant that transforms complex questions into comprehensive, cited reports by conducting iterative analysis using any LLM across diverse knowledge sources including academic databases, scientific repositories, web content, and private document collections. | 2025-06-11T21:24:15Z |
| 26 | [lsp-ai](https://github.com/SilasMarvin/lsp-ai) | 2814 | 95 | Rust | 33 | LSP-AI is an open-source language server that serves as a backend for AI-powered functionality, designed to assist and empower software engineers, not replace them. | 2025-01-07T22:17:38Z |
| 27 | [xTuring](https://github.com/stochasticai/xTuring) | 2653 | 201 | Python | 10 | Build, customize and control you own LLMs. From data pre-processing to fine-tuning, xTuring provides an easy way to personalize open-source LLMs. Join our discord community: https://discord.gg/TgHXuSJEk6 | 2024-09-23T09:40:48Z |
| 28 | [secret-llama](https://github.com/abi/secret-llama) | 2619 | 165 | TypeScript | 19 | Fully private LLM chatbot that runs entirely with a browser with no server needed. Supports Mistral and LLama 3. | 2024-06-05T02:04:17Z |
| 29 | [elia](https://github.com/darrenburns/elia) | 2176 | 136 | Python | 13 | A snappy, keyboard-centric terminal user interface for interacting with large language models. Chat with ChatGPT, Claude, Llama 3, Phi 3, Mistral, Gemma and more. | 2024-10-10T19:12:52Z |
| 30 | [json_repair](https://github.com/mangiucugna/json_repair) | 2101 | 97 | Python | 2 | A python module to repair invalid JSON from LLMs | 2025-06-06T08:05:12Z |
| 31 | [maid](https://github.com/Mobile-Artificial-Intelligence/maid) | 2020 | 214 | Dart | 13 | Maid is a cross-platform Flutter app for interfacing with GGUF / llama.cpp models locally, and with Ollama and OpenAI models remotely.  | 2025-05-28T04:49:58Z |
| 32 | [OnnxStream](https://github.com/vitoplantamura/OnnxStream) | 1953 | 88 | C++ | 58 | Lightweight inference library for ONNX files, written in C++. It can run Stable Diffusion XL 1.0 on a RPI Zero 2 (or in 298MB of RAM) but also Mistral 7B on desktops and servers. ARM, x86, WASM, RISC-V supported. Accelerated by XNNPACK. | 2025-05-13T19:34:45Z |
| 33 | [floneum](https://github.com/floneum/floneum) | 1906 | 101 | Rust | 42 | Instant, controllable, local pre-trained AI models in Rust | 2025-06-13T02:07:51Z |
| 34 | [Ollamac](https://github.com/kevinhermawan/Ollamac) | 1848 | 102 | Swift | 41 | Mac app for Ollama | 2025-03-12T22:28:22Z |
| 35 | [maxtext](https://github.com/AI-Hypercomputer/maxtext) | 1761 | 360 | Python | 49 | A simple, performant and scalable Jax LLM! | 2025-06-13T03:30:49Z |
| 36 | [dialoqbase](https://github.com/n4ze3m/dialoqbase) | 1758 | 280 | TypeScript | 39 | Create chatbots with ease | 2024-10-15T14:24:20Z |
| 37 | [papersgpt-for-zotero](https://github.com/papersgpt/papersgpt-for-zotero) | 1738 | 50 | JavaScript | 42 | Zotero chat PDF with AI, DeepSeek, GPT 4.1, ChatGPT, Claude, Gemini, Qwen3 | 2025-06-05T02:28:18Z |
| 38 | [modelfusion](https://github.com/vercel/modelfusion) | 1279 | 90 | TypeScript | 33 | The TypeScript library for building AI applications. | 2024-07-19T15:17:19Z |
| 39 | [search2ai](https://github.com/fatwang2/search2ai) | 1268 | 189 | JavaScript | 18 | Help your LLMs online | 2025-02-19T16:26:01Z |
| 40 | [aws-genai-llm-chatbot](https://github.com/aws-samples/aws-genai-llm-chatbot) | 1266 | 388 | TypeScript | 23 | A modular and comprehensive solution to deploy a Multi-LLM and Multi-RAG powered chatbot (Amazon Bedrock, Anthropic, HuggingFace, OpenAI, Meta, AI21, Cohere, Mistral) using AWS CDK on AWS | 2025-06-02T14:06:08Z |
| 41 | [LLM-Prompt-Library](https://github.com/abilzerian/LLM-Prompt-Library) | 1261 | 128 | Python | 0 | A playground of highly experimental prompts, tools & scripts for machine intelligence models from Apple, DeepSeek, OpenAI, Anthropic, Meta, Mistral, Google, xAI & others. Created Alex Bilzerian, maintained by Agents. | 2025-06-10T14:29:13Z |
| 42 | [nextjs-ollama-llm-ui](https://github.com/jakobhoeg/nextjs-ollama-llm-ui) | 1256 | 300 | TypeScript | 15 | Fully-featured web interface for Ollama LLMs | 2025-06-05T13:13:19Z |
| 43 | [gp.nvim](https://github.com/Robitx/gp.nvim) | 1199 | 100 | Lua | 44 | Gp.nvim (GPT prompt) Neovim AI plugin: ChatGPT sessions & Instructable text/code operations & Speech to text [OpenAI, Ollama, Anthropic, ..] | 2025-04-08T21:18:30Z |
| 44 | [airunner](https://github.com/Capsize-Games/airunner) | 1196 | 94 | Python | 13 | Offline inference engine for art, real-time voice conversations, LLM powered chatbots and automated workflows | 2025-06-13T00:17:24Z |
| 45 | [witsy](https://github.com/nbonamy/witsy) | 1176 | 89 | TypeScript | 11 | Witsy: desktop AI assistant / universal MCP client | 2025-06-12T21:57:34Z |
| 46 | [ai-dev-gallery](https://github.com/microsoft/ai-dev-gallery) | 1103 | 141 | C# | 55 | An open-source project for Windows developers to learn how to add AI with local models and APIs to Windows apps. | 2025-06-12T22:27:32Z |
| 47 | [poe-api-wrapper](https://github.com/snowby666/poe-api-wrapper) | 1091 | 147 | Python | 27 | 👾 A Python API wrapper for Poe.com. With this, you will have free access to GPT-4, Claude, Llama, Gemini, Mistral and more! 🚀 | 2025-03-07T20:07:31Z |
| 48 | [BaseAI](https://github.com/LangbaseInc/BaseAI) | 1072 | 93 | TypeScript | 4 | BaseAI — The Web AI Framework. The easiest way to build serverless autonomous AI agents with memory. Start building local-first, agentic pipes, tools, and memory. Deploy serverless with one command. | 2025-02-25T11:30:28Z |
| 49 | [generative-ai-use-cases](https://github.com/aws-samples/generative-ai-use-cases) | 1060 | 270 | TypeScript | 48 | Application implementation with business use cases for safely utilizing generative AI in business operations | 2025-06-13T03:29:41Z |
| 50 | [RisuAI](https://github.com/kwaroran/RisuAI) | 1059 | 192 | TypeScript | 74 | Make your own story. User-friendly software for LLM roleplaying | 2025-06-12T14:24:13Z |
| 51 | [chatd](https://github.com/BruceMacD/chatd) | 1039 | 72 | JavaScript | 26 | Chat with your documents using local AI | 2024-07-06T01:21:36Z |
| 52 | [paperless-gpt](https://github.com/icereed/paperless-gpt) | 1036 | 48 | Go | 61 | Use LLMs and LLM Vision (OCR) to handle paperless-ngx - Document Digitalization powered by AI | 2025-06-12T07:29:41Z |
| 53 | [graphrag-local-ollama](https://github.com/TheAiSingularity/graphrag-local-ollama) | 1009 | 157 | Python | 48 | Local models support for Microsoft's graphrag using ollama (llama3, mistral, gemma2 phi3)- LLM & Embedding extraction | 2024-09-30T02:43:30Z |
| 54 | [tt-metal](https://github.com/tenstorrent/tt-metal) | 915 | 194 | C++ | 2585 | :metal: TT-NN operator library, and TT-Metalium low level kernel programming model. | 2025-06-13T03:51:20Z |
| 55 | [MixtralKit](https://github.com/open-compass/MixtralKit) | 767 | 79 | Python | 12 | A toolkit for inference and evaluation of 'mixtral-8x7b-32kseqlen' from Mistral AI | 2023-12-15T19:10:55Z |
| 56 | [web-llm-chat](https://github.com/mlc-ai/web-llm-chat) | 765 | 129 | TypeScript | 10 | Chat with AI large language models running natively in your browser. Enjoy private, server-free, seamless AI conversations. | 2025-05-05T08:21:15Z |
| 57 | [Hexabot](https://github.com/Hexastack/Hexabot) | 742 | 132 | TypeScript | 129 | Hexabot is an open-source AI chatbot / agent builder. It allows you to create and manage multi-channel and multilingual chatbots / agents with ease.  | 2025-06-13T03:42:23Z |
| 58 | [mistral-common](https://github.com/mistralai/mistral-common) | 735 | 86 | Python | 18 | Official inference library for pre-processing of Mistral models | 2025-06-12T18:18:07Z |
| 59 | [fine-tune-mistral](https://github.com/abacaj/fine-tune-mistral) | 714 | 65 | Python | 3 | Fine-tune mistral-7B on 3090s, a100s, h100s | 2023-10-11T17:25:59Z |
| 60 | [ComfyUI-IF_AI_tools](https://github.com/if-ai/ComfyUI-IF_AI_tools) | 651 | 48 | Python | 51 | ComfyUI-IF_AI_tools is a set of custom nodes for ComfyUI that allows you to generate prompts using a local Large Language Model (LLM) via Ollama. This tool enables you to enhance your image generation workflow by leveraging the power of language models. | 2025-03-09T09:11:32Z |
| 61 | [client-python](https://github.com/mistralai/client-python) | 607 | 122 | Python | 15 | Python client library for Mistral AI platform | 2025-06-10T17:30:10Z |
| 62 | [BambooAI](https://github.com/pgalko/BambooAI) | 607 | 60 | Python | 11 | A Python library powered by Language Models (LLMs) for conversational data discovery and analysis. | 2025-06-13T02:27:06Z |
| 63 | [ai-commits-intellij-plugin](https://github.com/Blarc/ai-commits-intellij-plugin) | 603 | 45 | Kotlin | 17 | AI Commits for IntelliJ based IDEs/Android Studio. | 2025-06-09T07:12:35Z |
| 64 | [llm-finetuning](https://github.com/modal-labs/llm-finetuning) | 601 | 98 | Python | 1 | Guide for fine-tuning Llama/Mistral/CodeLlama models and more | 2025-05-07T01:11:58Z |
| 65 | [Owl](https://github.com/OwlAIProject/Owl) | 594 | 57 | Python | 6 | A personal wearable AI that runs locally | 2024-03-17T06:37:26Z |
| 66 | [llmcord](https://github.com/jakobdylanc/llmcord) | 578 | 123 | Python | 3 | Make Discord your LLM frontend ● Supports any OpenAI compatible API (Ollama, LM Studio, vLLM, OpenRouter, xAI, Mistral, Groq and more) | 2025-06-10T12:41:37Z |
| 67 | [mistral](https://github.com/stanford-crfm/mistral) | 573 | 52 | Python | 18 | Mistral: A strong, northwesterly wind: Framework for transparent and accessible large-scale language model training, built with Hugging Face 🤗  Transformers. | 2023-11-10T02:55:18Z |
| 68 | [rag-chatbot](https://github.com/datvodinh/rag-chatbot) | 538 | 84 | Python | 8 |  Chat with multiple PDFs locally | 2024-10-11T04:30:01Z |
| 69 | [embedJs](https://github.com/llm-tools/embedJs) | 522 | 64 | TypeScript | 15 | A NodeJS RAG framework to easily work with LLMs and embeddings | 2025-05-24T13:52:05Z |
| 70 | [DevoxxGenieIDEAPlugin](https://github.com/devoxx/DevoxxGenieIDEAPlugin) | 517 | 65 | Java | 54 | DevoxxGenie is a plugin for IntelliJ IDEA that uses local LLM's (Ollama, LMStudio, GPT4All, Jan and Llama.cpp) and Cloud based LLMs to help review, test, explain your project code. | 2025-06-06T14:11:04Z |
| 71 | [helix](https://github.com/helixml/helix) | 504 | 52 | Go | 127 | ♾️ Helix is a private GenAI stack for building AI applications with declarative pipelines, knowledge (RAG), API bindings, and first-class testing. | 2025-06-13T02:00:50Z |
| 72 | [ollama-voice-mac](https://github.com/apeatling/ollama-voice-mac) | 487 | 56 | Python | 8 | Mac compatible Ollama Voice | 2024-03-26T14:49:04Z |
| 73 | [obsidian-bmo-chatbot](https://github.com/longy2k/obsidian-bmo-chatbot) | 461 | 60 | TypeScript | 46 | Generate and brainstorm ideas while creating your notes using Large Language Models (LLMs) from Ollama, LM Studio, Anthropic, Google Gemini, Mistral AI, OpenAI, and more for Obsidian. | 2024-09-12T04:07:29Z |
| 74 | [aikit](https://github.com/sozercan/aikit) | 457 | 42 | Go | 22 | 🏗️ Fine-tune, build, and deploy open-source LLMs easily! | 2025-06-09T03:10:22Z |
| 75 | [LESS](https://github.com/princeton-nlp/LESS) | 454 | 46 | Jupyter Notebook | 16 | [ICML 2024] LESS: Selecting Influential Data for Targeted Instruction Tuning | 2024-10-20T03:11:58Z |
| 76 | [mlx-llm](https://github.com/riccardomusmeci/mlx-llm) | 444 | 30 | Python | 0 | Large Language Models (LLMs) applications and tools running on Apple Silicon in real-time with Apple MLX. | 2025-01-29T07:13:07Z |
| 77 | [bolna](https://github.com/voxos-ai/bolna) | 420 | 111 | Python | 28 | End-to-end platform for building voice first multimodal agents | 2024-10-28T05:40:38Z |
| 78 | [WorkflowAI](https://github.com/WorkflowAI/WorkflowAI) | 405 | 42 | Python | 1 | WorkflowAI is an open-source platform where product and engineering teams  collaborate to build and iterate on AI features. | 2025-06-13T03:39:38Z |
| 79 | [xllm](https://github.com/bobazooba/xllm) | 403 | 21 | Python | 6 | 🦖 X—LLM: Cutting Edge & Easy LLM Finetuning | 2024-01-17T16:43:39Z |
| 80 | [GPTPortal](https://github.com/Zaki-1052/GPTPortal) | 380 | 69 | JavaScript | 1 | A feature-rich portal to chat with GPT-4, Claude, Gemini, Mistral, & OpenAI Assistant APIs via a lightweight Node.js web app; supports customizable multimodality for voice, images, & files. | 2025-06-05T05:11:17Z |
| 81 | [fltr](https://github.com/moritztng/fltr) | 379 | 8 | Rust | 1 | Like grep but for natural language questions. Based on Mistral 7B or Mixtral 8x7B. | 2024-03-13T11:39:01Z |
| 82 | [yalm](https://github.com/andrewkchan/yalm) | 369 | 36 | C++ | 2 | Yet Another Language Model: LLM inference in C++/CUDA, no libraries except for I/O | 2025-06-07T01:32:14Z |
| 83 | [NeuralFlow](https://github.com/valine/NeuralFlow) | 365 | 16 | Python | 4 | Visualize the intermediate output of Mistral 7B | 2025-01-22T11:25:17Z |
| 84 | [KVQuant](https://github.com/SqueezeAILab/KVQuant) | 358 | 31 | Python | 14 | [NeurIPS 2024] KVQuant: Towards 10 Million Context Length LLM Inference with KV Cache Quantization | 2024-08-13T11:19:28Z |
| 85 | [edgen](https://github.com/edgenai/edgen) | 357 | 18 | Rust | 23 | ⚡  Edgen: Local, private GenAI server alternative to OpenAI. No GPU required. Run AI models locally: LLMs (Llama2, Mistral, Mixtral...), Speech-to-text (whisper) and many others. | 2024-05-23T14:21:38Z |
| 86 | [simple-openai](https://github.com/sashirestela/simple-openai) | 320 | 40 | Java | 6 | A Java library to use the OpenAI Api in the simplest possible way. | 2025-06-10T02:59:30Z |
| 87 | [OllamaKit](https://github.com/kevinhermawan/OllamaKit) | 309 | 37 | Swift | 5 | Ollama client for Swift | 2025-03-09T22:20:34Z |
| 88 | [LLaMa2lang](https://github.com/AI-Commandos/LLaMa2lang) | 309 | 35 | Python | 0 | Convenience scripts to finetune (chat-)LLaMa3 and other models for any language | 2024-06-17T14:00:13Z |
| 89 | [aicommit2](https://github.com/tak-bro/aicommit2) | 305 | 25 | TypeScript | 6 | A Reactive CLI that generates git commit messages with Ollama, ChatGPT, Gemini, Claude, Mistral and other AI | 2025-06-04T01:54:31Z |
| 90 | [END-TO-END-GENERATIVE-AI-PROJECTS](https://github.com/GURPREETKAURJETHRA/END-TO-END-GENERATIVE-AI-PROJECTS) | 296 | 88 | None | 0 | End to End Generative AI Industry Projects on LLM Models with Deployment_Awesome LLM Projects | 2025-01-24T07:20:37Z |
| 91 | [mistral](https://github.com/openstack/mistral) | 292 | 122 | Python | 0 | Workflow Service for OpenStack. Mirror of code maintained at opendev.org. | 2025-06-09T08:40:08Z |
| 92 | [nanodl](https://github.com/HMUNACHI/nanodl) | 287 | 11 | Python | 2 | A Jax-based library for building transformers, includes implementations of GPT, Gemma, LlaMa, Mixtral, Whisper, SWin, ViT and more. | 2024-08-28T21:24:22Z |
| 93 | [Heat](https://github.com/nathanborror/Heat) | 280 | 17 | Swift | 5 | An LLM agnostic desktop and mobile client. | 2025-05-08T20:34:10Z |
| 94 | [ai-playground](https://github.com/rokbenko/ai-playground) | 278 | 70 | Python | 0 | Code from tutorials presented on the "Code AI with Rok" YouTube channel | 2025-05-08T09:21:17Z |
| 95 | [llm-mistral-invoice-cpu](https://github.com/katanaml/llm-mistral-invoice-cpu) | 266 | 63 | Python | 0 | Data extraction with LLM on CPU | 2024-03-26T05:44:59Z |
| 96 | [Kolosal](https://github.com/KolosalAI/Kolosal) | 263 | 19 | C++ | 11 | Kolosal AI is an OpenSource and Lightweight alternative to LM Studio to run LLMs 100% offline on your device. | 2025-05-22T06:29:28Z |
| 97 | [voice-chat-ai](https://github.com/bigsk1/voice-chat-ai) | 262 | 58 | Python | 0 | 🎙️ Speak with AI - Run locally using Ollama, OpenAI, Anthropic or xAI - Speech uses XTTS, OpenAI, ElevenLabs or Kokoro | 2025-06-10T10:02:05Z |
| 98 | [unsaged](https://github.com/jorge-menjivar/unsaged) | 256 | 79 | TypeScript | 15 | Open source chat kit engineered for seamless interaction with AI models. | 2025-02-25T18:02:25Z |
| 99 | [ProX](https://github.com/GAIR-NLP/ProX) | 250 | 17 | Python | 1 | [ICML 2025] Programming Every Example: Lifting Pre-training Data Quality Like Experts at Scale | 2025-06-05T06:39:09Z |
| 100 | [picollm](https://github.com/Picovoice/picollm) | 248 | 14 | Python | 0 | On-device LLM Inference Powered by X-Bit Quantization | 2025-06-11T20:16:28Z |

